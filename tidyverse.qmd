# Working with dataframes {#sec-day4-tidyverse}

For an accompanying video, see `df.mp4`.

## Motivation

While base R is powerful, its syntax can be verbose and inconsistent for everyday data manipulation. The tidyverse offers a suite of packages that work seamlessly together, providing a coherent and intuitive framework for your workflow.

Instead of installing individual packages like **dplyr** or **tidyr** separately, the tidyverse metapackage installs the core packages and recommended dependencies all at once:

```{r}
if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}
library(tidyverse)
```

**Key Advantages:**

- **Readable Syntax:** Tidyverse functions replace cumbersome expressions (e.g., `test_df[test_df[["column"]] == "value", ]`) with cleaner, more intuitive code.
- **Pipe-Friendly:** Designed with the data object as the first argument, these functions work seamlessly with the pipe operator for streamlined chaining.
- **Consistent Interfaces:** Uniform parameter names and positions across functions reduce confusion and help prevent errors.
- **Predictable Behavior:** Standardized return types and design make outcomes more reliable and debugging easier.

At the heart of many analyses is the dataframe, and the tidyverse is built to simplify working with and transforming dataframes effectively.

## Displaying Dataframes in R

Working with large dataframes can be challenging if you inadvertently print all rows to the console.
Consider the following example:

```{r}
example_df <- data.frame(
  id = rep(paste0("id_", 1:500), each = 20),
  timepoint = rep(1:20, 500),
  disease_status = rep(
    sample(c("healthy", "diseased"), 20, replace = TRUE),
    each = 500
  ),
  blood_pressure = c(
    runif(20, 120, 140) |> round(),
    sample(c(NA, runif(19, 120, 140)), 9980, replace = TRUE)
  )
)
# Introduce a typo for demonstration
example_df[50, "disease_status"] <- "Healthy"
```

This dataframe contains 10,000 rows:

```{r}
nrow(example_df)
```

Printing the entire dataframe (e.g., simply typing `example_df`) would display all rows, which is both inconvenient and time-consuming. Instead, we typically use the `head()` function to preview just the first few rows:

```{r}
head(example_df)
```

However, constantly having to call `head()` is not ideal. A better solution is to convert the dataframe into a tibble.

### Enhancing Dataframe Display with `tibble`

The `tibble` package (a core part of the tidyverse) offers a more concise and informative display. When you print a tibble, it only shows the first 10 rows and includes data type information for each column. This is particularly useful because it lets you quickly verify, for example, whether `timepoint` is numeric or character—information that can be obscured in the default dataframe printout.

#### Installation and Conversion

First, ensure that the `tibble` package is installed and loaded:

```{r}
if (!requireNamespace("tibble", quietly = TRUE)) {
  install.packages("tibble")
}
library(tibble)
```

Convert your dataframe to a tibble using `as_tibble()`:

```{r}
# Check the class before conversion
class(example_df)

# Convert to tibble
example_df <- as_tibble(example_df)

# Check the class after conversion
class(example_df)
```

Now, simply typing `example_df` will display a neat summary of your data:

```{r}
example_df
```

This tidy display helps you catch issues like typos or unexpected data types early on. I generally load both `tibble` and `ggplot2` at the top of my scripts, and you can also create new dataframes directly as tibbles:

```{r}
new_tbl <- tibble(x = 1:5, y = rnorm(5))
new_tbl
```

Note that for a `tibble` object (i.e. a dataframe that has class `tbl_df`) to display as a tibble, the `tibble` package needs to be attached.
So always add `library(tibble)` to the top of your script.

A final, very nice feature of `tibbles` is that selecting one column using `df[, "column"]` will return a tibble, rather than a vector.
This is typically what we would expect:

```{r}
example_df[, "id"]
```

```{r}
class(example_df[, "id"])
```

### Exploring Data Columns with `view_cols`

Whilst `tibble`s provide a more informative display, they still only show the first few rows of each column.

Another useful tool is the `view_cols` function from the `UtilsDataRSV` package.
This function displays unique entries for each column—always showing any missing values (NAs)—so you can quickly identify anomalies such as typos or unexpected values.

To install the `UtilsDataRSV` package, use the following code:

```{r}
#| eval: false
if (!requireNamespace("remotes", quietly = TRUE)) {
  install.packages("remotes")
}
remotes::install_github("SATVILab/UtilsDataRSV")
```

Once installed, you can apply `view_cols` to your tibble to inspect the unique values in each column:

```{r}
UtilsDataRSV::view_cols(example_df)
```

`view_cols` is particularly helpful when you cannot easily inspect all the rows or columns of a dataframe.
For example, with 10,000 rows, it’s impractical to scroll through the entire dataset to:

- **Identify Typos:** In our example, the first ten rows may not reveal that `disease_status` contains three unique entries (e.g., `"healthy"`, `"diseased"`, and the typo `"Healthy"`).
- **Detect Missing Data:** It's easy to overlook missing values (NAs).
- **Verify Expected Values:** For instance, the `id` column should have 500 unique entries, and `view_cols` can help you confirm th

For a possibly more polished alternative, consider exploring the `skimr` package, which (I think) offers similar functionality.

You can also display the dataframe on its side, using `dplyr::glimpse()`:

```{r}
dplyr::glimpse(example_df)
```

## Pipe

- Essentially, the pipe is a rewrite of code, from

```{r}
#| eval: false
f(x,y)
```

to 

```{r}
#| eval: false
x |> f(y)
```

In other words, the object to the left of the pipe (`x`) becomes the first argument to the function on the right (`f`) and `y` becomes its second parameter.

As as silly example, this:

```{r}
test_vec <- 1:5
mean(test_vec[test_vec > 3], trim = 0.5)
```

is equivalent to this:

```{r}
test_vec[test_vec > 3] |>
  mean(trim = 0.5)
```

In terms of `f(x,y)`, `f` is `mean`, `x` is `test_vec[test_vec > 3]` and `y` is `trim = 0.5`.

The above examples are simply, and there is no great advantage to the pipe operator.

However, when you have chained operations, the pipe operator can make the code more readable.
For a realistic example, see [R4DS on the pipe](https://r4ds.hadley.nz/data-transform.html#sec-the-pipe), where they show a dramatic gain in readability from using the pipe.
To run their example, you will need to have the `flights` dataset from the `nycflights13` package and the `tidyverse` package attached.

To ensure this, first run the chunk below before running their example:

```{r}
pkg_vec <- c("tidyverse", "nycflights13", "tibble")
for (x in pkg_vec) {
  if (!requireNamespace(x, quietly = TRUE)) {
    install.packages(x)
  }
}
library(nycflights13)
library(tidyverse)
library(tibble)
data(flights, package = "nycflights13")
```

Their example involves many functions that we'll discuss in the rest of this chapter.

## Working with rows and columns

The `dplyr` package provides a suite of functions for manipulating dataframes, including selecting rows and columns, creating new columns, and summarizing data.

There is little point in re-writing excellent content, so I refer you to the [R4DS chapter on `dplyr`](https://r4ds.hadley.nz/data-transform) for a comprehensive introduction to the package.

### Summary

Here is a concise summary of the content on the `dplyr` section of R4DS.
For more examples, refer the excellent examples within each function's help file (e.g. `?filter`).

To run the examples below, you will need to attach the `nycflights13` package and the `tidyverse` package (or just the `dplyr` package).

```{r}
if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}
library(dplyr)
data(flights, package = "nycflights13")
flights
```

#### Rows

The rows functions select rows (`filter`), order rows (`arrange`), and select distinct rows (`distinct`).

- **filter()**: Keeps rows that meet specified conditions.

  ```{r}
  flights |> filter(month == 1)
  ```

- **arrange()**: Reorders rows based on column values.

  ```{r}
  flights |> arrange(dep_delay)
  ```

- **distinct()**: Returns unique rows or unique combinations of specified columns.

  ```{r}
  flights |> distinct(origin, dest)
  ```

#### Columns

The columns functions create new columns (`mutate`), select columns (`select`), rename columns (`rename`), and relocate columns (`relocate`).

- **select()**: Chooses and reorders specific columns.

  ```{r}
  flights |> select(year, month, day, dep_delay)
  ```

  - Selecting a range:
            
    ```{r}
    flights |> select(year:day)
    ```

  - Selecting all columns except some:

    ```{r}
    flights |> select(!year:arr_delay)
    ```

- **mutate()**: Creates new columns derived from existing ones.

  ```{r}
  flights |>
    mutate(speed = distance / air_time * 60) |>
    select(distance, air_time, speed)
  ```


- **rename()**: Changes column names without removing other columns.

  ```{r}
  flights |> rename(YEAR = year)
  ```

- **relocate()**: Moves columns to a new position within the data frame.

  ```{r}
  flights |> relocate(carrier, flight)
  ```

  - Moving the columns before a specified column:

    ```{r}
    flights |> relocate(carrier, flight, .before = year)
    ```

#### Groups & Summaries

The groups and summaries functions group data (`group_by`) and summarise data within groups (`summarise`).

- **group_by()**: Splits the data into groups based on one or more columns. The grouping is not visible, and does not create multiple dataframes. See `summarise` below for how to use the groups.

  ```{r}
  flights |> group_by(month)
  ```
  

- **summarise()**: Computes summary statistics for each group.

  ```{r}
  flights |> group_by(month) |> summarise(avg_delay = mean(dep_delay, na.rm = TRUE))
  ```

## Changing the shape of data

A key concept in data analysis is that of "tidy data".
A dataset is tidy when:

- Each variable is in its own column.
- Each observation is in its own row.
- Each cell contains a single value.

Consistent data structure simplifies analysis, leverages vectorized operations, and makes it easier to use tidyverse functions.

The `tidyr` package provides convenient tools for tidying data, such as `pivot_longer()` and `pivot_wider()`.

As before, I refer you to the [R4DS chapter on `tidyr`](https://r4ds.hadley.nz/data-tidy) for a comprehensive introduction to the package.

### Summary

Here is a concise summary of the key content on the `tidyr` section of R4DS.
For more examples, refer the excellent examples within each function's help file (e.g. `?pivot_longer`).

To run the examples below, you will need to attach the `tidyr` package and load the `billboard` and `cms_patient_experience` datasets.

```{r}
#| message: false
#| warning: false
#| results: hide
#| echo: true
if (!requireNamespace("tidyr", quietly = TRUE)) {
  install.packages("tidyr")
}
library(tidyr)
data(billboard, package = "tidyr")
data(cms_patient_experience, package = "tidyr")
```

- **pivot_longer():**  

  Converts data from wide to long format by gathering multiple columns into key-value pairs (results in fewer columns, more rows).

  Here is the `billboard` data before the transformation:

  ```{r}
  billboard
  ```

  Here is the `billboard` data after the transformation:

  ```{r}
  billboard |> 
    pivot_longer(
      cols = starts_with("wk"), # columns to pivot (display along rows)
      names_to = "week",  # new column for the column names
      values_to = "rank", # new column for the values
      values_drop_na = TRUE # drop rows with NA values
    )
  ```

- **pivot_wider():** 

  Transforms long data to wide format by spreading key-value pairs across columns (results in more columns, fewer rows).

  Here is the `cms_patient_experience` data before the transformation:

  ```{r}
  cms_patient_experience
  ```

  Here is the `cms_patient_experience` data after the transformation:

  ```{r}
  cms_patient_experience |> 
    pivot_wider(
      id_cols = c("org_pac_id", "org_nm"), # columns to keep as identifiers
      names_from = measure_cd, # column to spread (unique entries become columns)
      values_from = prf_rate # column to use for values (values become cell contents)
    )
  ```

  - Columns not specified in `id_cols`, `names_from`, or `values_from` are dropped (such as `measure_nm` in this example).

## Joining dataframes

The `dplyr` package also provides functions for joining dataframes, such as `left_join()` and `inner_join()`.

The full-length notes are in the [R4DS chapter on `joins`](https://r4ds.hadley.nz/joins).

### Key Joining Concepts in dplyr

Data analysis typically involves combining multiple data frames. Joins let you connect tables using shared keys, which can be primary keys (unique identifiers in one table) and foreign keys (variables that reference primary keys in another).

### Summary

Again, here is a concise summary of the R4DS content on the `joins` section.
More examples are available in the help files for each function (e.g. `?left_join`).

To run the examples below, attach the `dplyr` package and create and load the following datasets:

```{r}
library(dplyr)
data("flights", package = "nycflights13")
flights2 <- flights |> 
  select(year, time_hour, origin, dest, tailnum, carrier)
data("airlines", package = "nycflights13")
data("planes", package = "nycflights13")
df1 <- tibble(key = c(1, 2, 2), val_x = c("x1", "x2", "x3"))
df2 <- tibble(key = c(1, 2, 2), val_y = c("y1", "y2", "y3"))
```

Here is what these datasets look like:

```{r}
flights2
```

```{r}
airlines
```

```{r}
planes
```

```{r}
df1
```

```{r}
df2
```

#### Mutating Joins

Mutating joins add new columns from one data frame to another based on matching key values.
They share a common interface:

- **left_join()**: Keeps all rows from the left table and adds matching columns from the right table.  

  ```{r}
  # Add full airline names to flights2 data
  flights2 |> left_join(airlines)
  ```

- **inner_join()**: Keeps only rows with matching keys in both tables. 

  ```{r}
  # Only keep rows where both x and y have a matching key
  df1 |> inner_join(df2)
  ```

  - In the example above, `dplyr` emits a warning as two rows in `df1` (those with `key` value `2`) have two matches in `df2` (those with `key` value `2`). Often, this is an error (your data isn't what you expect it to be), but that is the example they showed.

- **Specifying Keys:**  

  By default, join functions match on columns with the same name. Use `join_by()` to specify different keys:

  ```{r}
  flights2 |> left_join(planes, join_by(tailnum))
  ```

#### Filtering Joins

Filtering joins select rows from one table based solely on whether they have a match in another table.

- **semi_join()**: Keeps rows in `x` that have at least one match in `y` (does not add columns from `y`).

  ```{r}
  # Keep only origin airports that appear in flights2
  airports |> semi_join(flights2, join_by(faa == origin))
  ```

- **anti_join()**: Keeps rows in `x` that have no match in `y`.

  ```{r}
  # Find tail numbers in flights2 that are missing from planes
  flights2 |> anti_join(planes, join_by(tailnum)) |> distinct(tailnum)
  ```

These joining functions provide a powerful and flexible way to integrate data from different sources, ensuring that your analyses are both comprehensive and accurate.